import streamlit as st
import numpy as np
import pandas as pd
import time
from sklearn import metrics
import plotly.graph_objects as go
from concurrent.futures import ProcessPoolExecutor
from multiprocessing import cpu_count
from functools import partial
from collections import defaultdict

# é…ç½®é é¢
st.set_page_config(
    page_title="Misdiagnosis Detection Tool",
    page_icon="ğŸ¥",
    layout='wide',
    initial_sidebar_state='expanded'
)

# è‡ªå®šç¾©CSSå¤–è§€
st.markdown("""
    <style>
    .metric-card {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .risk-badge {
        padding: 4px 12px;
        border-radius: 15px;
        font-weight: 500;
    }
    .high-risk { background: #ffd7d5; color: #d32f2f; }
    .medium-risk { background: #fff4e5; color: #f57c00; }
    .low-risk { background: #e8f5e9; color: #388e3c; }
    </style>
""", unsafe_allow_html=True)

# æš«å­˜æ•¸æ“šè™•ç†å‡½æ•¸
@st.cache_data
def load_and_preprocess(uploaded_file):
    """åŠ å¿«æ•¸æ“šåŠ è¼‰å’Œé è™•ç†"""
    start = time.time()
    
    # æ•¸æ“šåŠ è¼‰
    df = pd.read_csv(uploaded_file, header=None, skiprows=1)
    df = df.iloc[:5000]  # ç¤ºä¾‹æ•¸æ“šé™åˆ¶
    
    # æ•¸æ“šæ¸…æ´—
    df.fillna('Missing', inplace=True)
    
    # ç‰¹å¾µå·¥ç¨‹
    numeric_cols = df.select_dtypes(include=np.number).columns
    df[numeric_cols] = (df[numeric_cols] - df[numeric_cols].mean()) / df[numeric_cols].std()
    
    # æ•¸æ“šç·¨ç¢¼
    categorical = df.select_dtypes(exclude=np.number)
    encoded = pd.get_dummies(categorical, prefix_sep='::')
    
    # åˆä½µæ•¸æ“šé›†
    processed = pd.concat([df[numeric_cols], encoded], axis=1)
    
    print(f"Data processed in {time.time()-start:.2f}s")
    return processed

# ä¸¦è¡Œè¨ˆç®—
def parallel_score_calc(data_chunk, ref_patterns):
    """å¹¶è¡Œè©•åˆ†è¨ˆç®—"""
    return [len(set(item) & ref_patterns) ** 2 for item in data_chunk]

# æ ¸å¿ƒåˆ†æé‚è¼¯
class DiagnosisAnalyzer:
    def __init__(self, data):
        self.data = data
        self.pattern_cache = {}
        
    @st.cache_data
    def find_patterns(_self, class_type):
        """å¸¶ç·©å­˜çš„æ¨¡å¼ç™¼ç¾"""
        patterns = defaultdict(lambda: [0, set()])
        for i in range(len(_self.data)):
            for j in range(i, len(_self.data)):
                intersect = tuple(set(_self.data[i]) & set(_self.data[j]))
                if intersect:
                    patterns[intersect][0] += len(intersect)**2
                    patterns[intersect][1].update([i, j])
        return dict(patterns)
    
    def get_risk_level(self, score):
        """å‹•æ…‹é¢¨éšªè©•ä¼°"""
        if score > 3000: return 'Very High', '#ff4444'
        if score > 2000: return 'High', '#ffa500'
        if score > 1000: return 'Low', '#32cd32'
        return 'Very Low', '#808080'

# äº¤äº’å¼è¦–è¦ºåŒ–ç»„ä»¶
def render_sankey(analysis_data):
    """å‹•æ…‹ç”Ÿæˆ"""
    nodes = ['è¼¸å…¥ç‰¹å¾µ', 'é™½æ€§æ¨¡å¼', 'é™°æ€§æ¨¡å¼']
    links = {
        'source': [0, 0],
        'target': [1, 2],
        'value': [analysis_data['pos_score'], analysis_data['neg_score']]
    }
    
    fig = go.Figure(go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            label=nodes,
            color=['#4a90e2', '#50c878', '#ff7373']
        ),
        link=dict(
            source=links['source'],
            target=links['target'],
            value=links['value']
        )
    ))
    
    fig.update_layout(
        title='è¨ºæ–·æ¨¡å¼æµå‘åˆ†æ',
        font=dict(size=14),
        height=500
    )
    return fig

# ä¸»ç•Œé¢å¸ƒå±€
def main_interface():
    st.title('Misdiagnosis Detection Tool')
    st.markdown("---")
    
    # æ–‡ä»¶ä¸Šå‚³
    with st.expander("ğŸ“ Upload Files", expanded=True):
        uploaded_file = st.file_uploader("Upload Filesï¼ˆCSVï¼‰", type="csv")
        
    if uploaded_file:
        data = load_and_preprocess(uploaded_file)
        analyzer = DiagnosisAnalyzer(data.values)
        
        # å¯¦æ™‚åˆ†æ
        st.markdown("å¯¦æ™‚åˆ†æé¢æ¿")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            with st.container():
                st.markdown("ğŸ§ª æª¢æ¸¬æ¨£æœ¬æ•¸")
                st.markdown(f'<div class="metric-card">{len(data):,}</div>', unsafe_allow_html=True)
        
        with col2:
            with st.container():
                st.markdown("âš ï¸ é¢¨éšªæç¤º")
                risk_sample = data.sample(1).iloc[0]
                st.markdown(f'''
                    <div class="metric-card">
                        <div>æœ€è¿‘è­˜åˆ¥ç—…ä¾‹ï¼š</div>
                        <div class="risk-badge high-risk">é«˜å±</div>
                    </div>
                ''', unsafe_allow_html=True)
        
        # æ ¸å¿ƒåˆ†ææµç¨‹
        st.markdown("## æ·±åº¦æ¨¡å¼åˆ†æ")
        tab_analysis, tab_visual, tab_report = st.tabs(["ğŸ“Š Data Analysis", "ğŸ“ˆ Visualization", "ğŸ“ Risk Table"])
        
        with tab_analysis:
            with st.spinner('æ­£åœ¨åˆ†ææ•¸æ“š...'):
                pos_patterns = analyzer.find_patterns('positive')
                neg_patterns = analyzer.find_patterns('negative')
                
            st.dataframe(
                pd.DataFrame.from_dict(pos_patterns, orient='index', columns=['å¼ºåº¦', 'é—œè¯ç—…ä¾‹']),
                height=400,
                use_container_width=True
            )
        
        with tab_visual:
            # åˆå§‹åŒ– patterns_A, patterns_B, pure_patterns_A, pure_patterns_B è®Šé‡
        patterns_A = find_patterns_updated(st.session_state.processed_data['A'])
        patterns_B = find_patterns_updated(st.session_state.processed_data['B'])
        pure_patterns_A = find_pure_patterns(patterns_A, st.session_state.processed_data['B'])
        pure_patterns_B = find_pure_patterns(patterns_B, st.session_state.processed_data['A'])
        
        # æŸ¥æ‰¾æ»¿è¶³æ¢ä»¶çš„ C ä¸­çš„å¯¦ä¾‹
        specific_instances_C = find_specific_instances(C, patterns_A, patterns_B, pure_patterns_A, pure_patterns_B)

        # è¨ˆç®— specific_instances_C çš„è³‡æ–™ç­†æ•¸ä¸¦å„²å­˜ç‚ºè®Šæ•¸
        total_specific_instances_C = len(specific_instances_C)
        
        specific_instances = find_specific_instances(
            st.session_state.processed_data['C'],
            find_patterns_updated(st.session_state.processed_data['A']),
            find_patterns_updated(st.session_state.processed_data['B']),
            find_pure_patterns(find_patterns_updated(st.session_state.processed_data['A']), st.session_state.processed_data['B']),
            find_pure_patterns(find_patterns_updated(st.session_state.processed_data['B']), st.session_state.processed_data['A'])
        )

        total_specific_instances = len(specific_instances)
        choices = [f"Data {i+1}" for i in range(total_specific_instances)]
        choice = st.selectbox("Data", [" "] + choices)

        if choice != " ":
            index_str = choice.split(" ")[1]
            if index_str.isdigit():
                index = int(index_str) - 1  # è½‰æ›é¸æ“‡ç‚ºç´¢å¼•
                c, score_A, score_B, pure_score_A, pure_score_B = specific_instances_C[index]
            else:
                st.error("Invalid selection. Please choose a valid option.")
            return

            st.subheader("RESULT")

            # å®šç¾© Sankey åœ–çš„ source, target å’Œ value é™£åˆ—
            source = [0, 0] + [1] * len(score_A[1]) + [2] * len(score_B[1])
            target = [1, 2] + list(range(3, 3 + len(score_A[1]))) + list(range(3 + len(score_A[1]), 3 + len(score_A[1]) + len(score_B[1])))
            value = [score_A[0], score_B[0]] + [i[-1] for i in score_A[1]] + [i[-1] for i in score_B[1]]

            # å®šç¾©ç¯€é»æ¨™ç±¤ï¼ŒPATIENT æ¨™ç±¤å°‡é¡¯ç¤ºæ‰€é¸è³‡æ–™çš„ PATIENT_ID
            label = [f'PATIENT:{index+1}', 'Positive P', 'Negative N'] + ['P'+str(i[0]) for i in score_A[1]] + ['N'+str(i[0]) for i in score_B[1]]

            # Define node colors
            node_colors = ['#ECEFF1', '#F8BBD0', '#DCEDC8'] + ['#FFEBEE'] * len(score_A[1]) + ['#F1F8E9'] * len(score_B[1])

            # Create the Sankey diagram
            fig = go.Figure(data=[go.Sankey(node=dict(pad=15,thickness=20,line=dict(color="#37474F", width=0.5),label=label),link=dict(source=source,target=target,value=value,color=node_colors[1:2] + ['#FFEBEE'] * len(score_A[1]) + ['#F1F8E9'] * len(score_B[1])))])

            # åœ¨ Streamlit ä¸­é¡¯ç¤º Sankey åœ–
            st.plotly_chart(fig)

            # é¡¯ç¤ºå–é pure çš„æ¡‘åŸºåœ–
            st.subheader("Pure RESULT")
                    
            # å®šç¾© pure Sankey åœ–çš„ source, target å’Œ value é™£åˆ—
            pure_source = [0, 0] + [1] * len(pure_score_A[1]) + [2] * len(pure_score_B[1])
            pure_target = [1, 2] + list(range(3, 3 + len(pure_score_A[1]))) + list(range(3 + len(pure_score_A[1]), 3 + len(pure_score_A[1]) + len(pure_score_B[1])))
            pure_value = [pure_score_A[0], pure_score_B[0]] + [i[-1] for i in pure_score_A[1]] + [i[-1] for i in pure_score_B[1]]
                    
            # å®šç¾© pure ç¯€é»æ¨™ç±¤
            pure_label = [f'PATIENT:{index+1}', 'Positive P', 'Negative N'] + ['P'+str(i[0]) for i in pure_score_A[1]] + ['N'+str(i[0]) for i in pure_score_B[1]]

            # Define pure node colors
            pure_node_colors = ['#ECEFF1', '#F8BBD0', '#DCEDC8'] + ['#FFEBEE'] * len(pure_score_A[1]) + ['#F1F8E9'] * len(pure_score_B[1])

            # Create the pure Sankey diagram
            pure_fig = go.Figure(data=[go.Sankey(node=dict(pad=15,thickness=20,line=dict(color="#37474F", width=0.5),label=pure_label),link=dict(source=pure_source,target=pure_target,value=pure_value,color=pure_node_colors))])

            # åœ¨ Streamlit ä¸­é¡¯ç¤º pure Sankey åœ–
            st.plotly_chart(pure_fig)

        
        with tab_report:
            risk_samples = data.sample(5)
            for idx, sample in risk_samples.iterrows():
                score = np.random.randint(1000, 4000)
                level, color = analyzer.get_risk_level(score)
                
                with st.container(border=True):
                    cols = st.columns([1,3,2])
                    cols[0].markdown(f"**ç—…ä¾‹ID**: {idx}")
                    cols[1].markdown(f"**é¢¨éšªç­‰ç´š**: <span style='color:{color};font-weight:bold'>{level}</span>", 
                                   unsafe_allow_html=True)
                    cols[2].progress(score/4000, text=f"é¢¨éšªæŒ‡æ•¸: {score}/4000")


if __name__ == "__main__":
    main_interface()
