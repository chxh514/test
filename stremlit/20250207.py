import streamlit as st
import numpy as np
import pandas as pd
import time
from sklearn import metrics
import plotly.graph_objects as go
from concurrent.futures import ProcessPoolExecutor
from multiprocessing import cpu_count
from functools import partial
from collections import defaultdict

# é…ç½®é é¢
st.set_page_config(
    page_title="Misdiagnosis Detection Tool",
    page_icon="ğŸ¥",
    layout='wide',
    initial_sidebar_state='expanded'
)

# è‡ªå®šç¾©CSSå¤–è§€
st.markdown("""
    <style>
    .metric-card {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .risk-badge {
        padding: 4px 12px;
        border-radius: 15px;
        font-weight: 500;
    }
    .high-risk { background: #ffd7d5; color: #d32f2f; }
    .medium-risk { background: #fff4e5; color: #f57c00; }
    .low-risk { background: #e8f5e9; color: #388e3c; }
    </style>
""", unsafe_allow_html=True)

# æš«å­˜æ•¸æ“šè™•ç†å‡½æ•¸
@st.cache_data
def load_and_preprocess(uploaded_file):
    """åŠ å¿«æ•¸æ“šåŠ è¼‰å’Œé è™•ç†"""
    start = time.time()

    # æ•¸æ“šåŠ è¼‰
    df = pd.read_csv(uploaded_file, header=None, skiprows=1)
    df = df.iloc[:5000]  # ç¤ºä¾‹æ•¸æ“šé™åˆ¶

    # æ•¸æ“šæ¸…æ´—
    df.fillna('Missing', inplace=True)

    # ç‰¹å¾µå·¥ç¨‹
    numeric_cols = df.select_dtypes(include=np.number).columns
    df[numeric_cols] = (df[numeric_cols] - df[numeric_cols].mean()) / df[numeric_cols].std()

    # æ•¸æ“šç·¨ç¢¼
    categorical = df.select_dtypes(exclude=np.number)
    encoded = pd.get_dummies(categorical, prefix_sep='::')

    # åˆä½µæ•¸æ“šé›†
    processed = pd.concat([df[numeric_cols], encoded], axis=1)

    print(f"Data processed in {time.time()-start:.2f}s")
    return processed

# ä¸¦è¡Œè¨ˆç®—
def parallel_score_calc(data_chunk, ref_patterns):
    """å¹¶è¡Œè©•åˆ†è¨ˆç®—"""
    return [len(set(item) & ref_patterns) ** 2 for item in data_chunk]

# æ ¸å¿ƒåˆ†æé‚è¼¯
class DiagnosisAnalyzer:
    def __init__(self, data):
        self.data = data
        self.pattern_cache = {}

    @st.cache_data
    def find_patterns(_self, class_type):
        """å¸¶ç·©å­˜çš„æ¨¡å¼ç™¼ç¾"""
        patterns = defaultdict(lambda: [0, set()])
        for i in range(len(_self.data)):
            for j in range(i, len(_self.data)):
                intersect = tuple(set(_self.data[i]) & set(_self.data[j]))
                if intersect:
                    patterns[intersect][0] += len(intersect)**2
                    patterns[intersect][1].update([i, j])
        return dict(patterns)

    def get_risk_level(self, score):
        """å‹•æ…‹é¢¨éšªè©•ä¼°"""
        if score > 3000: return 'Very High', '#ff4444'
        if score > 2000: return 'High', '#ffa500'
        if score > 1000: return 'Low', '#32cd32'
        return 'Very Low', '#808080'

# äº¤äº’å¼è¦–è¦ºåŒ–ç»„ä»¶
def render_sankey(analysis_data):
    """å‹•æ…‹ç”Ÿæˆ"""
    nodes = ['è¼¸å…¥ç‰¹å¾µ', 'é™½æ€§æ¨¡å¼', 'é™°æ€§æ¨¡å¼']
    links = {
        'source': [0, 0],
        'target': [1, 2],
        'value': [analysis_data['pos_score'], analysis_data['neg_score']]
    }

    fig = go.Figure(go.Sankey(
        node=dict(
            pad=15,
            thickness=20,
            label=nodes,
            color=['#4a90e2', '#50c878', '#ff7373']
        ),
        link=dict(
            source=links['source'],
            target=links['target'],
            value=links['value']
        )
    ))

    fig.update_layout(
        title='è¨ºæ–·æ¨¡å¼æµå‘åˆ†æ',
        font=dict(size=14),
        height=500
    )
    return fig

# ä¸»ç•Œé¢å¸ƒå±€
def main_interface():
    st.title('Misdiagnosis Detection Tool')
    st.markdown("---")

    # æ–‡ä»¶ä¸Šå‚³
    with st.expander("ğŸ“ Upload Files", expanded=True):
        uploaded_file = st.file_uploader("Upload Filesï¼ˆCSVï¼‰", type="csv")

    if uploaded_file:
        data = load_and_preprocess(uploaded_file)
        analyzer = DiagnosisAnalyzer(data.values)

        # å¯¦æ™‚åˆ†æ
        st.markdown("å¯¦æ™‚åˆ†æé¢æ¿")
        col1, col2, col3 = st.columns(3)

        with col1:
            with st.container():
                st.markdown("ğŸ§ª æª¢æ¸¬æ¨£æœ¬æ•¸")
                st.markdown(f'<div class="metric-card">{len(data):,}</div>', unsafe_allow_html=True)

        with col2:
            with st.container():
                st.markdown("âš ï¸ é¢¨éšªæç¤º")
                risk_sample = data.sample(1).iloc[0]
                st.markdown(f'''
                    <div class="metric-card">
                        <div>æœ€è¿‘è­˜åˆ¥ç—…ä¾‹ï¼š</div>
                        <div class="risk-badge high-risk">é«˜å±</div>
                    </div>
                ''', unsafe_allow_html=True)

        # æ ¸å¿ƒåˆ†ææµç¨‹
        st.markdown("## æ·±åº¦æ¨¡å¼åˆ†æ")
        tab_analysis, tab_visual, tab_report = st.tabs(["ğŸ“Š Data Analysis", "ğŸ“ˆ Visualization", "ğŸ“ Risk Table"])

        with tab_analysis:
            with st.spinner('æ­£åœ¨åˆ†ææ•¸æ“š...'):
                pos_patterns = analyzer.find_patterns('positive')
                neg_patterns = analyzer.find_patterns('negative')

            st.dataframe(
                pd.DataFrame.from_dict(pos_patterns, orient='index', columns=['å¼ºåº¦', 'é—œè¯ç—…ä¾‹']),
                height=400,
                use_container_width=True
            )

        with tab_visual:
            sample_data = data.sample(1).iloc[0].values
            analysis_result = {
                'pos_score': len(sample_data) * 150,
                'neg_score': len(sample_data) * 75
            }
            st.plotly_chart(render_sankey(analysis_result), use_container_width=True)

        with tab_report:
    # Create a list to store the data
            report_data = []

    for idx, (c, score_A, score_B, pure_score_A, pure_score_B) in enumerate(specific_instances_C):
        risk_score = max(pure_score_A[0], pure_score_B[0])  # ä½¿ç”¨å–é pure çš„åˆ†æ•¸ä¾†åˆ¤æ–·é¢¨éšªé«˜ä½
        if risk_score < 1000:
            risk_level = "Very Low"
            status = ""
        elif risk_score < 2000:
            risk_level = "Low"
            status = ""
        elif risk_score < 3000:
            risk_level = "High"
            status = "âš ï¸"
        else:
            risk_level = "Very High"
            status = "âš ï¸"
        report_data.append({
            "Status": status,
            "ID": idx + 1,
            "NS": pure_score_A[0],  # ä½¿ç”¨å–é pure çš„åˆ†æ•¸
            "PS": pure_score_B[0],  # ä½¿ç”¨å–é pure çš„åˆ†æ•¸
            "Label": ClassT[idx],
            "Misdiagnosis Risk": risk_level
        })

    df_risk = pd.DataFrame(report_data)
    styled_df = df_risk.style.apply(highlight_risk, axis=1)
    st.dataframe(styled_df, use_container_width=False, height=600)

    # Add a button to download the DataFrame as a CSV file
    csv = df_risk.to_csv(index=False)
    st.download_button(label="Download Risk Table as CSV", data=csv, file_name='risk_table.csv', mime='text/csv')
if __name__ == "__main__":
    main_interface()
